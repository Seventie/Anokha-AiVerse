# ğŸš€ CareerAI - AI-Powered Career Development Companion

<div align="center">

![CareerAI Banner](Images/Whisk_8c48828dea189739602491e7850d8817dr.jpeg)

# CareerAI â€“ Automate, Learn, and Grow ğŸš€

![Python](https://img.shields.io/badge/python-3.11+-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-0.104-green)
![Architecture](https://img.shields.io/badge/architecture-agentic_AI-purple)


---

[ğŸš€ Quick Start](#-quick-start) â€¢
[ğŸ¤– AI Agents](#-ai-agents) â€¢
[ğŸ–¼ Demo](#-screenshots)

</div>

***

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Workflow](#-complete-workflow)
- [AI Agent System](#-ai-agents)
- [Database Design](#-database-architecture)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Automation](#-automation--scheduling)
- [Screenshots](#-screenshots)
- [Roadmap](#-roadmap)
- [Contributing](#-contributing)

***

## ğŸŒŸ Overview

**CareerAI** is an intelligent, fully-automated career development platform that acts as your **long-term AI companion**. Built with a sophisticated multi-agent orchestration system, it automates every aspect of your career journey - from personalized learning roadmaps to AI-powered interviews, job matching, cold email outreach, and continuous learning through daily reflections.

### **What Makes CareerAI Different?**

ğŸ¤– **Fully Autonomous** - 8 specialized AI agents working 24/7 for you  
ğŸ§  **Long-term Memory** - Learns from every interaction via vector embeddings  
â° **Smart Automation** - Auto-schedules tasks, sends emails, finds jobs  
ğŸ¯ **Integrated Ecosystem** - Syncs with Gmail, Google Calendar  
ğŸ¤ **Voice-First Interviews** - Natural conversation with AI interviewer  
ğŸ“Š **Data-Driven Insights** - Multi-database architecture for deep analytics  

![Platform Overview](./docs/images/platform- âœ¨ Key Features

### ğŸ“ **Smart Resume Onboarding**

![Resume Upload](./docs/images/resume-dious form-filling, just upload your resume:

- **Automatic Parsing** - Extract education, experience, skills, projects
- **AI Verification** - Review and confirm extracted data
- **Multi-database Sync** - Saves to PostgreSQL, Neo4j, ChromaDB simultaneously
- **Instant Profile Creation** - Complete registration in 2 minutes

**Flow:** Upload PDF/DOCX â†’ AI parses â†’ Pre-filled form â†’ User verifies â†’ Profile ready

***

### ğŸ¤– **Orchestrated AI Agent System**

![Agent System](./docs/images/agent- specialized agents** coordinated by an Orchestrator using **LangGraph + LangChain**:

| Agent | Runs | Purpose |
|-------|------|---------|
| **Orchestrator** | Every 12 hours | Coordinates all agents, triggers automation |
| **Profile Agent** | On-demand | Syncs user data across 3 databases |
| **Resume Agent** | On-demand | Parses resumes, analyzes ATS score, compares versions |
| **Roadmap Agent** | Auto + On-demand | Creates learning schedules, syncs Google Calendar |
| **Interview Agent** | On-demand | Conducts voice interviews with Whisper + Piper TTS |
| **Opportunities Agent** | Every 12 hours | Scrapes jobs, matches with user skills |
| **Cold Email Agent** | Every 3 days | Sends personalized outreach via Gmail API |
| **Journal Agent** | Daily | Analyzes reflections, builds long-term memory |
| **Summary Agent** | Real-time | Aggregates dashboard data, scrapes quotes/news |

***

### ğŸ“š **Automated Learning Roadmap**

![Roadmap Calendar](./docs/images/roadmap-generated learning path that **manages itself**:

**How it Works:**
1. Analyzes skill gaps using Neo4j knowledge graph
2. Generates 7-day learning schedule
3. **Automatically creates Google Calendar events**
4. User marks tasks complete (syncs to dashboard)
5. If delayed 10+ days â†’ **Auto-reschedules** tasks
6. Sends Gmail reminders for upcoming milestones

**Manual Override:** User can request custom rescheduling anytime

**Integration:** 
- âœ… Google Calendar (2-way sync)
- âœ… Gmail notifications
- âœ… Dashboard progress tracking

***

### ğŸ¤ **AI Voice Interview Simulator**

![Interview Room](./docs/images/interview-room.pngd interviews with **real-time AI evaluation**:

**Interview Flow:**

```
User Schedules Interview
         â†“
Interview Agent Retrieves Pre-stored Questions (PostgreSQL)
         â†“
Plays Question Audio (Piper TTS)
         â†“
User Answers (Voice/Text)
         â†“
Transcription (Whisper STT)
         â†“
LLM Analyzes Answer (Groq API)
         â†“
Follow-up Question (Context-aware)
         â†“
Repeat â†’ Final Scoring â†’ Detailed Feedback
```

**Features:**
- **Pre-stored Question Bank** - 100+ role-specific questions
- **Dynamic Follow-ups** - LLM generates contextual questions
- **Conversation Memory** - Temporary field stores interview context
- **Multi-modal Input** - Voice OR text answers
- **Instant Feedback** - STAR method analysis, improvement tips
- **Historical Analytics** - Track improvement over time

**Tech Stack:** Whisper (STT) + Piper TTS + Groq LLM + PostgreSQL

***

### ğŸ’¼ **Automated Job Matching (Every 12 Hours)**

![Job Dashboard](./docs/images/job- opportunity** - AI finds and ranks jobs while you sleep:

**Automation Workflow:**

```
[Every 12 Hours]
Orchestrator Triggers Opportunities Agent
         â†“
Scrapes Job Boards (LinkedIn, Indeed, Glassdoor)
         â†“
Saves Jobs to PostgreSQL
         â†“
Generates Embeddings in ChromaDB
         â†“
Vector Similarity Search with User Profile
         â†“
Filters by Neo4j Skill Requirements
         â†“
Ranks by Compatibility Score
         â†“
Updates Dashboard Home Page
```

**Matching Algorithm:**
```
Score = Skills Match (40%) + Experience (30%) + 
        Location (15%) + Salary (10%) + Culture (5%)
```

**Dashboard View:** Top 20 matches with match score, reasons, one-click apply tracking

***

### ğŸ“§ **Automated Cold Email Outreach**

![Cold Email]( sends personalized cold emails every 3 days** (with your permission):

**How It Works:**
1. User provides target list (companies/people)
2. User opts-in to automation
3. Every 3 days:
   - Cold Email Agent activates
   - Queries target list from PostgreSQL
   - LLM generates personalized emails based on user skills
   - Sends via **Gmail API**
   - Tracks responses in database
4. User reviews sent emails and responses in dashboard

**Customization:**
- Email templates can be reviewed before automation
- Pause/resume anytime
- Track open rates and replies

***

### ğŸ“ **AI Learning Journal - Your Long-term Companion**

![Journal](./docs/images/journal.png build a **persistent memory** of your journey:

**Journal Agent Features:**
- **Sentiment Analysis** - Tracks mood and motivation trends
- **LLM Insights** - Extracts key learnings and patterns
- **Vector Embeddings** - Stores entries in ChromaDB for memory retrieval
- **Long-term Learning** - AI remembers past reflections to personalize guidance
- **Pattern Recognition** - Identifies what strategies work best for you

**Example Insights:**
- "You learn best on Tuesday mornings"
- "React projects boost your confidence more than Python"
- "You've been feeling overwhelmed - let's adjust your roadmap pace"

**Flow:** Write entry â†’ LLM analyzes â†’ Sentiment score â†’ Embeddings stored â†’ Insights generated

***

### ğŸ“„ **Resume Analyzer & Comparator**

![Resume Analyzer](./docs/images/resume powerful resume tools:**

**1. ATS Compatibility Checker**
- Upload resume + job description
- AI calculates match score
- Highlights missing keywords
- Suggests improvements

**2. Resume Comparison**
- Compare two versions side-by-side
- See which performs better for specific roles
- A/B testing recommendations

**3. Resume Enhancement**
- AI rewrites bullet points for impact
- Quantifies achievements
- Optimizes formatting

***

### ğŸ“Š **Unified Dashboard - Everything Connected**

![Dashboard Home](./docs/images/dashboard-** aggregates data from all systems in real-time:

**Dashboard Sections:**

| Section | Data Source | Update Frequency |
|---------|-------------|------------------|
| **Daily Quote** | Web scraper | Daily |
| **Industry News** | News API (user's goal) | Real-time |
| **Roadmap Progress** | Google Calendar + PostgreSQL | Real-time |
| **Interview Stats** | PostgreSQL | Real-time |
| **Job Matches** | Opportunities Agent | Every 12 hours |
| **Cold Email Status** | Gmail API + PostgreSQL | Every 3 days |
| **Journal Insights** | Journal Agent | Daily |
| **Skill Growth** | Neo4j + ChromaDB | Real-time |

**Everything is connected** - marking roadmap complete updates calendar, interview scores influence job matching, journal sentiment adjusts roadmap pace.

***

## ğŸ—ï¸ System Architecture

### **High-Level Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FRONTEND (React 18 + TypeScript)                â”‚
â”‚   Landing | Login | Dashboard | Interview | Roadmap     â”‚
â”‚         JWT Auth | MediaRecorder API                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ REST API
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           BACKEND API (FastAPI + Python 3.11)           â”‚
â”‚                                                          â”‚
â”‚  Routes: /auth /profile /interview /roadmap             â”‚
â”‚          /opportunities /journal /resume                â”‚
â”‚                                                          â”‚
â”‚  Middleware: JWT + CORS + Background Scheduler          â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚         â”‚          â”‚          â”‚            â”‚
   â–¼         â–¼          â–¼          â–¼            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PostgreSQL Neo4jâ”‚ ChromaDB â”‚ Whisper â”‚ â”‚Piper TTS â”‚
â”‚ (Facts)â”‚(Graph)â”‚ (Memory)â”‚ â”‚  (STT) â”‚ â”‚ (Voice)  â”‚
â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚         â”‚          â”‚          â”‚            â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   LangGraph Orchestrator â”‚
           â”‚  (Coordinates 8 Agents)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

![Architecture Diagram](./docs/images/ **Multi-Agent Orchestration (LangGraph + LangChain)**

```
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚  ORCHESTRATOR       â”‚
                  â”‚  (Supervisor Agent) â”‚
                  â”‚                     â”‚
                  â”‚  â€¢ Runs every 12hrs â”‚
                  â”‚  â€¢ Routes requests  â”‚
                  â”‚  â€¢ Manages state    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Profile Agent â”‚     â”‚Resume Agent  â”‚     â”‚Roadmap Agent â”‚
â”‚              â”‚     â”‚              â”‚     â”‚              â”‚
â”‚â€¢ Sync 3 DBs  â”‚     â”‚â€¢ Parse docs  â”‚     â”‚â€¢ Neo4j query â”‚
â”‚â€¢ Update graphâ”‚     â”‚â€¢ ATS score   â”‚     â”‚â€¢ Cal sync    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
        â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Interview     â”‚     â”‚Opportunities â”‚     â”‚Cold Email    â”‚
â”‚Agent         â”‚     â”‚Agent         â”‚     â”‚Agent         â”‚
â”‚              â”‚     â”‚              â”‚     â”‚              â”‚
â”‚â€¢ STT/TTS     â”‚     â”‚â€¢ Job scrapingâ”‚     â”‚â€¢ Gmail API   â”‚
â”‚â€¢ LLM eval    â”‚     â”‚â€¢ Vector matchâ”‚     â”‚â€¢ Every 3 daysâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                    â”‚                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  Journal Agent   â”‚
                    â”‚  Summary Agent   â”‚
                    â”‚                  â”‚
                    â”‚â€¢ Sentiment       â”‚
                    â”‚â€¢ Embeddings      â”‚
                    â”‚â€¢ Dashboard data  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

***

## ğŸ”„ Complete Workflow

### **1. User Registration Flow**

![Registration Flow](./docs/images/registration-
         â†“
Click "Get Started"
         â†“
Upload Resume (PDF/DOCX)
         â†“
Resume Agent Parses Document
         â†“
Auto-fills Registration Form
  â€¢ Email, Name, Location
  â€¢ Education (institution, degree, dates)
  â€¢ Experience (role, company, duration)
  â€¢ Skills (technical + soft)
  â€¢ Projects (title, tech stack)
         â†“
User Reviews & Verifies Data
         â†“
Submit Registration
         â†“
[Backend Processing]
  1. Save to PostgreSQL (user, education, experience, skills, projects)
  2. Generate JWT token
  3. Background Task: Profile Agent syncs to Neo4j
  4. Background Task: Create embeddings in ChromaDB
         â†“
User Redirected to Dashboard
```

**Result:** Complete profile created in < 2 minutes

***

### **2. Automated Job Matching (Every 12 Hours)**

![Job Automation](./docs/images/job-t 00:00 & 12:00 Daily]
         â†“
Orchestrator Triggers Opportunities Agent
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Opportunities Agent Workflow            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. Scrape Job Boards:                  â”‚
â”‚    â€¢ LinkedIn Jobs API                  â”‚
â”‚    â€¢ Indeed (BeautifulSoup)            â”‚
â”‚    â€¢ Glassdoor (Selenium)              â”‚
â”‚                                         â”‚
â”‚ 2. Parse & Clean Data:                â”‚
â”‚    â€¢ Title, Company, Location          â”‚
â”‚    â€¢ Salary, Requirements              â”‚
â”‚    â€¢ Posted Date, Source URL           â”‚
â”‚                                         â”‚
â”‚ 3. Store in PostgreSQL:                â”‚
â”‚    â€¢ Table: opportunities              â”‚
â”‚    â€¢ Deduplicate existing jobs         â”‚
â”‚                                         â”‚
â”‚ 4. Generate Embeddings:                â”‚
â”‚    â€¢ Job description â†’ ChromaDB        â”‚
â”‚    â€¢ Store with metadata               â”‚
â”‚                                         â”‚
â”‚ 5. Match with User Profile:           â”‚
â”‚    â€¢ Vector search (user skills)       â”‚
â”‚    â€¢ Neo4j skill requirement filter    â”‚
â”‚    â€¢ Calculate compatibility score     â”‚
â”‚                                         â”‚
â”‚ 6. Rank Top 20 Matches                â”‚
â”‚                                         â”‚
â”‚ 7. Update Dashboard                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
User Sees New Job Matches on Dashboard
```

**User Experience:** Log in anytime to see fresh, personalized job matches

***

### **3. Automated Learning Roadmap**

![Roadmap Automation](./docs/images/roadmap-automation.pngonths"]
         â†“
Roadmap Agent Workflow:
         â†“
1. Query Neo4j for Skill Gaps
   â€¢ User current skills: [React, Node.js]
   â€¢ Target role requires: [React, Node.js, PostgreSQL, Docker, AWS]
   â€¢ Gaps identified: [PostgreSQL, Docker, AWS]
         â†“
2. Generate Learning Path (Neo4j Graph Traversal)
   â€¢ Week 1-2: PostgreSQL fundamentals
   â€¢ Week 3-4: Docker containerization
   â€¢ Week 5-7: AWS basics (EC2, S3, RDS)
   â€¢ Week 8: Capstone project
         â†“
3. Create 7-Day Schedule
   â€¢ Break down into daily tasks
   â€¢ Allocate time based on user availability
         â†“
4. Sync to Google Calendar (via API)
   â€¢ Create events with descriptions
   â€¢ Set reminders
         â†“
5. Store in PostgreSQL
   â€¢ Table: roadmap_tasks
   â€¢ Track status: pending, in_progress, completed, delayed
         â†“
User Receives Gmail Notification: "Your roadmap is ready!"
         â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    ONGOING AUTOMATION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         â†“
User Marks Task Complete (Dashboard)
         â†“
Updates: PostgreSQL + Google Calendar
         â†“
[If task delayed 10+ days]
         â†“
Roadmap Agent Auto-reschedules
         â†“
Sends Gmail: "Your schedule has been adjusted"
         â†“
[User can manually request rescheduling anytime]
```

**Key Integrations:**
- Google Calendar API (OAuth 2.0)
- Gmail API (send notifications)
- PostgreSQL (task tracking)

***

### **4. AI Interview Session**

![Interview Flow](./docs/images/interview-   â†“
Interview Setup:
  â€¢ Select role (e.g., "Backend Engineer")
  â€¢ Choose difficulty (Easy/Medium/Hard)
  â€¢ Duration (15/30/45 mins)
         â†“
Interview Agent Initializes:
         â†“
1. Retrieve Pre-stored Questions (PostgreSQL)
   â€¢ Filter by role + difficulty
   â€¢ Select 10-15 questions
         â†“
2. Create Interview Session
   â€¢ Generate interview_id
   â€¢ Initialize temporary conversation context field
         â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    INTERVIEW LOOP (For Each Question)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         â†“
3. Play Question Audio
   â€¢ Text â†’ Piper TTS â†’ WAV file
   â€¢ Stream to frontend
         â†“
4. User Answers (Voice or Text)
   â€¢ If voice: MediaRecorder â†’ WebM blob
         â†“
5. Transcribe Answer (Whisper STT)
   â€¢ WebM â†’ WAV conversion
   â€¢ Whisper model transcribes
         â†“
6. Store in Temporary Context
   â€¢ Append to conversation history
   â€¢ Pass to LLM for context awareness
         â†“
7. LLM Evaluates Answer (Groq API)
   Prompt:
   """
   Question: {question}
   Answer: {transcribed_answer}
   Conversation history: {context}
   
   Evaluate based on:
   - Relevance (1-10)
   - STAR structure (1-10)
   - Technical accuracy (1-10)
   - Communication clarity (1-10)
   
   Generate:
   - Score
   - Feedback
   - Follow-up question (if needed)
   """
         â†“
8. Save Response to PostgreSQL
   â€¢ interview_responses table
   â€¢ Link to question_id
         â†“
9. Display Feedback to User (Real-time)
         â†“
10. Generate Follow-up Question (LLM)
    â€¢ Based on conversation context
    â€¢ Adaptive difficulty
         â†“
[Repeat Loop for Next Question]
         â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    INTERVIEW COMPLETION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         â†“
11. Calculate Final Score
    â€¢ Weighted average across all questions
         â†“
12. Generate Comprehensive Feedback
    â€¢ Strengths
    â€¢ Improvement areas
    â€¢ Recommended resources
         â†“
13. Save to PostgreSQL
    â€¢ interviews table (status: completed)
         â†“
14. Display Results Dashboard
    â€¢ Score breakdown
    â€¢ Question-by-question review
    â€¢ Historical comparison
```

**Tech Stack:**
- **Whisper Base** (offline, 74M parameters)
- **Piper TTS** (en_US-lessac-medium model)
- **Groq LLM** (question generation + evaluation)
- **PostgreSQL** (question bank + results)
- **Temporary Context Field** (in-memory conversation state)

***

### **5. Cold Email Automation (Every 3 Days)**

![Cold Email Flow](./docs/images/      â†“
User Navigates to "Cold Email" Section
         â†“
1. Upload Target List (CSV/Manual Entry)
   â€¢ Columns: Name, Email, Company, Role
         â†“
2. Review AI-Generated Email Template
   Sample:
   """
   Hi {name},
   
   I noticed {company} is hiring for {role}. With my experience
   in {user_skills}, I believe I could contribute to...
   
   [Personalized based on user profile]
   """
         â†“
3. Opt-in to Automation
   â€¢ User agrees to send every 3 days
   â€¢ Set max emails per batch (e.g., 10)
         â†“
4. Target List Saved to PostgreSQL
   â€¢ Table: cold_email_targets
   â€¢ Status: pending
         â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    AUTOMATED WORKFLOW (Every 3 Days)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         â†“
[Background Scheduler - 9:00 AM Every 3 Days]
         â†“
Orchestrator Triggers Cold Email Agent
         â†“
1. Query PostgreSQL for Pending Targets
   â€¢ Filter: status = 'pending'
   â€¢ Limit: user-defined batch size
         â†“
2. For Each Target:
   a. Retrieve User Profile from PostgreSQL
   b. LLM Generates Personalized Email
      Prompt:
      """
      User skills: {skills}
      User projects: {projects}
      Target: {name} at {company}
      Target role: {role}
      
      Generate a compelling cold email introducing
      the user and expressing interest in {role}.
      Keep it concise (150 words).
      """
   c. Store Generated Email in PostgreSQL
         â†“
3. Send via Gmail API
   â€¢ OAuth 2.0 authentication
   â€¢ Use user's Gmail account
   â€¢ Add to "Sent" folder
         â†“
4. Update Status in PostgreSQL
   â€¢ Status: sent
   â€¢ Timestamp: sent_at
         â†“
5. Track Responses
   â€¢ Gmail API watches for replies
   â€¢ Updates status: replied
         â†“
User Views Dashboard:
  â€¢ Emails sent: 30
  â€¢ Replies received: 5
  â€¢ Open rate: 40%
         â†“
[User can pause/resume automation anytime]
```

**Key Features:**
- **User Control:** Review templates before automation
- **Rate Limiting:** Max emails per batch to avoid spam
- **Response Tracking:** Gmail API monitors replies
- **Personalization:** LLM customizes each email

***

### **6. Daily Journal â†’ Long-term Memory**

![Journal Memory](./docs/images/journal-         â†“
User Navigates to "Journal" Tab
         â†“
Writes Reflection:
"""
Today I completed the PostgreSQL module. It was challenging at
first, but the hands-on project helped me understand joins better.
I feel more confident now. Tomorrow I'll start Docker.
"""
         â†“
User Clicks "Save Entry"
         â†“
Journal Agent Workflow:
         â†“
1. Store Raw Text in PostgreSQL
   â€¢ Table: journal_entries
   â€¢ Timestamp, user_id, entry_text
         â†“
2. Sentiment Analysis (Transformers/BERT)
   â€¢ Positive/Negative/Neutral score
   â€¢ Confidence level
   â€¢ Result: Positive (0.85 confidence)
         â†“
3. LLM Extracts Insights (Groq API)
   Prompt:
   """
   Analyze this journal entry:
   {entry_text}
   
   Extract:
   - Key learnings
   - Skills practiced
   - Emotions/sentiment
   - Challenges faced
   - Next actions
   """
   
   Result:
   â€¢ Learning: PostgreSQL joins
   â€¢ Skill: Database querying
   â€¢ Emotion: Confident
   â€¢ Challenge: Initially confusing
   â€¢ Next: Docker module
         â†“
4. Generate Embeddings (Sentence Transformers)
   â€¢ Convert entry to 768-dim vector
   â€¢ Store in ChromaDB
   â€¢ Metadata: date, sentiment, skills, user_id
         â†“
5. Update PostgreSQL
   â€¢ Add sentiment_score, extracted_insights
         â†“
6. Build Long-term Memory
   â€¢ ChromaDB enables semantic search
   â€¢ "When did user learn PostgreSQL?" â†’ Retrieves this entry
   â€¢ "What challenges did user face?" â†’ Historical patterns
         â†“
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    LONG-TERM COMPANION BEHAVIOR
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         â†“
[Next Day - User Asks: "I'm struggling with Docker networking"]
         â†“
Journal Agent Queries ChromaDB:
  â€¢ Semantic search: "docker challenges"
  â€¢ Retrieves past similar struggles
         â†“
LLM Generates Personalized Response:
"""
I remember when you started PostgreSQL, you also found the
concepts challenging at first. But after the hands-on project,
you felt much more confident. 

For Docker networking, I recommend trying a similar approach:
build a small multi-container app to see how networks work
in practice. Based on your learning style, you prefer
hands-on over theory.
"""
         â†“
Result: AI remembers past patterns and adapts guidance
```

**Memory Persistence:**
- **ChromaDB** stores ALL journal entries as vectors
- **Semantic Search** enables contextual memory retrieval
- **LLM** synthesizes insights from historical data
- **Long-term Companion** learns user over weeks/months

***

## ğŸ—„ï¸ Database Architecture

### **Three-Tier Database Strategy**

![Database Strategy](./docs/images/database-SQL - Relational Facts**

**Purpose:** Store structured, transactional data

**Key Tables:**

```sql
-- Authentication
users (id, email, hashed_password, full_name, created_at)

-- Profile
education (user_id, institution, degree, major, start_date, end_date)
experience (user_id, role, company, duration, description)
skills (user_id, skill, category, level, verified)
projects (user_id, title, description, tech_stack, url)

-- Career Planning
career_goals (user_id, target_role, timeline, status)
roadmap_tasks (user_id, task, due_date, status, calendar_event_id)

-- Interview System
interviews (id, user_id, role, difficulty, score, status)
interview_questions (id, interview_id, question_text, audio_path)
interview_responses (id, question_id, answer_text, score, feedback)

-- Opportunities
opportunities (id, title, company, location, salary, source, scraped_at)
user_opportunity_interactions (user_id, opportunity_id, status, applied_at)

-- Cold Email
cold_email_targets (id, user_id, name, email, company, status)
cold_email_history (id, target_id, email_body, sent_at, replied_at)

-- Journal
journal_entries (id, user_id, entry_text, sentiment_score, insights, created_at)

-- Calendar Integration
calendar_events (id, user_id, event_id, title, start_time, synced_at)
```

**Why PostgreSQL?**
- âœ… ACID compliance for transactional data
- âœ… Complex queries with JOINs
- âœ… Strong consistency guarantees
- âœ… Mature ecosystem (Alembic migrations)

***

### **2. Neo4j - Knowledge Graph**

**Purpose:** Model relationships between skills, roles, resources

**Graph Schema:**

```cypher
// Node Types
(:User {id, name, target_role, timeline})
(:Skill {name, category, difficulty, demand_score})
(:Role {title, seniority, industry, avg_salary})
(:Resource {title, type, url, difficulty, duration})
(:Company {name, size, industry, location})
(:Project {title, description, skills_used})

// Relationship Types
(:User)-[:HAS_SKILL {level, verified, acquired_date}]->(:Skill)
(:User)-[:TARGETS {timeline, priority}]->(:Role)
(:User)-[:WORKED_AT {duration, role}]->(:Company)
(:User)-[:COMPLETED]->(:Project)

(:Role)-[:REQUIRES {importance: 1-10, years_exp}]->(:Skill)
(:Skill)-[:PREREQUISITE_FOR {order}]->(:Skill)
(:Resource)-[:TEACHES {effectiveness: 1-10}]->(:Skill)
(:Company)-[:OFFERS]->(:Role)
(:Project)-[:DEMONSTRATES]->(:Skill)
```

**Example Queries:**

```cypher
// Find skill gaps for user targeting "Full Stack Developer"
MATCH (u:User {id: $user_id})-[:HAS_SKILL]->(userSkills:Skill)
MATCH (target:Role {title: "Full Stack Developer"})-[:REQUIRES]->(requiredSkills:Skill)
WHERE NOT (u)-[:HAS_SKILL]->(requiredSkills)
RETURN requiredSkills.name AS skill_gap,
       requiredSkills.importance AS priority
ORDER BY priority DESC

// Find learning path from current skill to target skill
MATCH (current:Skill {name: "React"}),
      (target:Skill {name: "AWS"})
MATCH path = shortestPath((current)-[:PREREQUISITE_FOR*]->(target))
RETURN path, length(path) AS steps

// Recommend resources for skill gap
MATCH (skill:Skill {name: "Docker"})<-[:TEACHES]-(resource:Resource)
RETURN resource.title, resource.url, resource.effectiveness
ORDER BY resource.effectiveness DESC
LIMIT 5
```

**Why Neo4j?**
- âœ… Natural representation of skill relationships
- âœ… Fast graph traversal for pathfinding
- âœ… Flexible schema for evolving ontology
- âœ… Cypher query language optimized for relationships

***

### **3. ChromaDB - Vector Embeddings (Memory)**

**Purpose:** Semantic search and long-term memory retrieval

**Collections:**

```python
# Collection 1: Resume Embeddings
resume_embeddings
  â€¢ Documents: Full resume text
  â€¢ Embeddings: 1536-dim vectors (OpenAI ada-002)
  â€¢ Metadata: user_id, uploaded_at, file_name
  â€¢ Use case: Semantic job matching

# Collection 2: User Conversation History
conversation_history
  â€¢ Documents: All interview Q&A, journal entries, chat logs
  â€¢ Embeddings: 768-dim vectors (Sentence Transformers)
  â€¢ Metadata: user_id, timestamp, conversation_type, sentiment
  â€¢ Use case: Long-term companion memory

# Collection 3: Job Description Embeddings
job_embeddings
  â€¢ Documents: Job descriptions from scraping
  â€¢ Embeddings: 1536-dim vectors
  â€¢ Metadata: opportunity_id, company, role, posted_date
  â€¢ Use case: Vector similarity search for job matching

# Collection 4: Learning Resource Embeddings
resource_embeddings
  â€¢ Documents: Course descriptions, tutorial summaries
  â€¢ Embeddings: 1536-dim vectors
  â€¢ Metadata: resource_id, skill, difficulty, platform
  â€¢ Use case: Personalized resource recommendations

# Collection 5: Journal Entry Embeddings
journal_embeddings
  â€¢ Documents: Daily journal reflections
  â€¢ Embeddings: 768-dim vectors
  â€¢ Metadata: user_id, date, sentiment_score, extracted_skills
  â€¢ Use case: Semantic memory retrieval (long-term companion)
```

**Example Usage:**

```python
# Job Matching via Vector Search
user_profile_embedding = generate_embedding(
    f"Skills: {user_skills}, Experience: {user_experience}"
)

similar_jobs = chromadb.job_embeddings.query(
    query_embeddings=[user_profile_embedding],
    n_results=50,
    where={"location": {"$eq": "San Francisco"}}
)

# Long-term Memory Retrieval
query = "When did I struggle with React hooks?"
results = chromadb.journal_embeddings.query(
    query_texts=[query],
    n_results=5,
    where={"user_id": {"$eq": user_id}}
)
# Returns: Past journal entries mentioning React hooks struggles
```

**Why ChromaDB?**
- âœ… Lightweight, embedded vector database
- âœ… Fast similarity search (HNSW algorithm)
- âœ… No separate server needed
- âœ… Python-native (easy integration with FastAPI)

***

### **Database Synchronization Flow**

```
User Action (e.g., Update Skills)
         â†“
1. Save to PostgreSQL (Source of Truth)
   â€¢ ACID transaction
   â€¢ skills table updated
         â†“
2. Background Task: Profile Agent Triggers
         â†“
3. Sync to Neo4j
   â€¢ Create/Update (:User)-[:HAS_SKILL]->(:Skill)
   â€¢ Update skill levels
         â†“
4. Generate Embeddings
   â€¢ Updated profile text â†’ Embedding
   â€¢ Store in ChromaDB (resume_embeddings)
         â†“
5. Trigger Dependent Agents
   â€¢ Roadmap Agent: Recalculate skill gaps
   â€¢ Opportunities Agent: Re-rank job matches
         â†“
All 3 databases now in sync
```

***

## ğŸ’» Technology Stack

### **Backend**

**Core Framework:**
- FastAPI 0.104+ (async API)
- Python 3.11+ (type hints, performance)
- Uvicorn (ASGI server)
- Pydantic 2.0+ (data validation)

**Databases:**
- **PostgreSQL 15** - Relational data (SQLAlchemy ORM)
- **Neo4j 5.0+** - Knowledge graph (py2neo driver)
- **ChromaDB 0.4+** - Vector embeddings (persistent client)

**AI/ML:**
- **Groq API** - LLM (fast inference)
- **LangChain 0.1+** - Agent framework
- **LangGraph** - Multi-agent orchestration
- **Whisper Base** - Speech-to-text (offline, 74M params)
- **Piper TTS** - Text-to-speech (en_US-lessac model)
- **Sentence Transformers** - Embeddings (all-MiniLM-L6-v2)
- **Transformers** - Sentiment analysis (BERT)

**Authentication & Security:**
- JWT (JSON Web Tokens)
- bcrypt (password hashing)
- OAuth 2.0 (Google Calendar/Gmail)

**Background Jobs:**
- APScheduler (cron-like scheduling)
- FastAPI BackgroundTasks

**Web Scraping:**
- BeautifulSoup4 (HTML parsing)
- Selenium (dynamic content)
- aiohttp (async HTTP)

**File Processing:**
- PyPDF2 (PDF parsing)
- python-docx (Word documents)
- python-multipart (file uploads)

**Database Migrations:**
- Alembic (PostgreSQL schema versioning)

***

### **Frontend**

**Core:**
- React 18 (concurrent rendering)
- TypeScript 5 (type safety)
- Vite 5 (fast dev server)

**UI Framework:**
- TailwindCSS 3.4 (utility-first CSS)
- Lucide React (icon library)
- Framer Motion (animations)

**State Management:**
- React Hooks (useState, useEffect, useContext)
- Context API (global state)

**Audio/Video:**
- MediaRecorder API (voice recording)
- Web Audio API (audio processing)
- HTMLAudioElement (playback)

**HTTP Client:**
- Axios (API requests)
- JWT token management

***

### **External Integrations**

**Google APIs:**
- Google Calendar API (OAuth 2.0, event CRUD)
- Gmail API (OAuth 2.0, send emails, read replies)

**Job Boards:**
- LinkedIn Jobs (API + scraping)
- Indeed (web scraping)
- Glassdoor (Selenium automation)

***

## ğŸš€ Quick Start

### **Prerequisites**

- Python 3.11+
- Node.js 18+
- PostgreSQL 15+
- Neo4j 5.0+ (Neo4j Desktop or Docker)
- Git

***

### **Installation**

**1. Clone Repository**

```bash
git clone https://github.com/Seventie/Anokha-AiVerse.git
cd Anokha-AiVerse
```

***

**2. Backend Setup**

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install all dependencies
pip install -r requirements.txt
pip install -r requirements_opportunities.txt
pip install -r req_interview.txt
pip install -r req_extra.txt
```

***

**3. Download AI Models**

```bash
# Whisper (Speech-to-Text)
python -c "import whisper; whisper.load_model('base')"

# Piper TTS (Text-to-Speech)
# Download from: https://github.com/rhasspy/piper/releases
# Place en_US-lessac-medium.onnx in backend/models/piper/

# Or use setup script (Linux/Mac)
chmod +x setup_local_models.sh
./setup_local_models.sh
```

***

**4. Environment Configuration**

Create `backend/.env`:

```env
# API Keys
OPENAI_API_KEY=your_openai_key_here        # For embeddings
GROQ_API_KEY=your_groq_key_here            # For LLM

# Database URLs
DATABASE_URL=postgresql://user:password@localhost:5432/careerai
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# JWT Secret
SECRET_KEY=your_super_secret_jwt_key_here_min_32_chars
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ChromaDB
CHROMA_PERSIST_DIRECTORY=./chroma_db

# File Storage
UPLOAD_DIR=./uploads
MAX_UPLOAD_SIZE=10485760  # 10MB

# AI Model Paths
WHISPER_MODEL_PATH=./models/whisper/base.pt
PIPER_MODEL_PATH=./models/piper/en_US-lessac-medium.onnx

# Google APIs (for Calendar & Gmail)
GOOGLE_CLIENT_ID=your_google_oauth_client_id
GOOGLE_CLIENT_SECRET=your_google_oauth_client_secret
GOOGLE_REDIRECT_URI=http://localhost:8000/api/auth/google/callback

# Scheduler
SCHEDULER_ENABLED=true
JOB_SCRAPING_INTERVAL_HOURS=12
COLD_EMAIL_INTERVAL_DAYS=3
```

***

**5. Initialize Databases**

```bash
# PostgreSQL - Create database
createdb careerai

# Run migrations
alembic upgrade head

# Seed with demo data (optional)
python init_db.py

# Neo4j - Start Neo4j Desktop or Docker
docker run -d --name neo4j \
  -p 7474:7474 -p 7687:7687 \
  -e NEO4J_AUTH=neo4j/your_password \
  neo4j:5.0

# Initialize knowledge graph
python app/services/graph_builder.py
```

***

**6. Frontend Setup**

```bash
cd ../frontend

# Install dependencies
npm install

# Create environment file
cat > .env.local << EOF
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
EOF
```

***

**7. Run Application**

**Terminal 1 - Backend:**

```bash
cd backend
source venv/bin/activate
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend:**

```bash
cd frontend
npm run dev
```

**Access Application:**
- ğŸŒ Frontend: http://localhost:5173
- ğŸ”Œ Backend API: http://localhost:8000
- ğŸ“š API Docs: http://localhost:8000/docs
- ğŸ—„ï¸ Neo4j Browser: http://localhost:7474

![Installation Success](./docs/images/installation- â° Automation & Scheduling

### **Background Scheduler Configuration**

CareerAI runs **automated tasks** using APScheduler:

**1. Job Scraping (Every 12 Hours)**

```python
# app/main.py
from apscheduler.schedulers.asyncio import AsyncIOScheduler

scheduler = AsyncIOScheduler()

@scheduler.scheduled_job('cron', hour='0,12')
async def scrape_jobs():
    """Runs at 00:00 and 12:00 daily"""
    logger.info("Starting job scraping...")
    await opportunities_agent.scrape_and_match_all_users()
```

**2. Cold Email Outreach (Every 3 Days)**

```python
@scheduler.scheduled_job('cron', day='*/3', hour='9')
async def send_cold_emails():
    """Runs at 9:00 AM every 3 days"""
    logger.info("Sending cold emails...")
    await cold_email_agent.process_pending_emails()
```

**3. Roadmap Auto-Rescheduling (Daily Check)**

```python
@scheduler.scheduled_job('cron', hour='8')
async def check_delayed_tasks():
    """Runs at 8:00 AM daily"""
    logger.info("Checking delayed roadmap tasks...")
    await roadmap_agent.reschedule_delayed_tasks(delay_threshold_days=10)
```

**4. Dashboard Data Sync (Every 6 Hours)**

```python
@scheduler.scheduled_job('cron', hour='*/6')
async def update_dashboards():
    """Runs every 6 hours"""
    logger.info("Updating user dashboards...")
    await summary_agent.refresh_all_dashboards()
```

***

## ğŸ“‚ Project Structure

```
Anokha-AiVerse/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/                     # AI Agent System
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base_agent.py          # Base agent class
â”‚   â”‚   â”‚   â”œâ”€â”€ supervisor_agent.py     # Orchestrator
â”‚   â”‚   â”‚   â”œâ”€â”€ profile_agent.py        # User profile sync
â”‚   â”‚   â”‚   â”œâ”€â”€ resume_agent.py         # Resume parsing & analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ interview_agent.py      # Interview conductor
â”‚   â”‚   â”‚   â”œâ”€â”€ roadmap_agent.py        # Learning path generator
â”‚   â”‚   â”‚   â”œâ”€â”€ opportunities_agent.py  # Job scraping & matching
â”‚   â”‚   â”‚   â”œâ”€â”€ journal_agent.py        # Reflection analyzer
â”‚   â”‚   â”‚   â””â”€â”€ summary_agent.py        # Dashboard aggregator
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ routes/                     # API Endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                 # Login, register, JWT
â”‚   â”‚   â”‚   â”œâ”€â”€ profile.py              # User profile CRUD
â”‚   â”‚   â”‚   â”œâ”€â”€ resume.py               # Resume upload & analysis
â”‚   â”‚   â”‚   â”œâ”€â”€ interview.py            # Interview sessions
â”‚   â”‚   â”‚   â”œâ”€â”€ roadmap.py              # Learning roadmap
â”‚   â”‚   â”‚   â”œâ”€â”€ opportunities.py        # Job search & apply
â”‚   â”‚   â”‚   â”œâ”€â”€ journal.py              # Journal entries
â”‚   â”‚   â”‚   â”œâ”€â”€ dashboard.py            # Dashboard data
â”‚   â”‚   â”‚   â””â”€â”€ knowledge_graph.py      # Neo4j queries
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/                   # Business Logic
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_db.py             # Neo4j connection
â”‚   â”‚   â”‚   â”œâ”€â”€ vector_db.py            # ChromaDB client
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_builder.py        # Neo4j initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ hybrid_graph_service.py # Multi-DB orchestration
â”‚   â”‚   â”‚   â”œâ”€â”€ user_graph_sync.py      # User â†’ Neo4j sync
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_service.py          # Groq API wrapper
â”‚   â”‚   â”‚   â”œâ”€â”€ interview_llm_service.py# Interview-specific LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ interview_service.py    # Interview logic
â”‚   â”‚   â”‚   â”œâ”€â”€ stt_service.py          # Whisper STT
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_service.py          # Piper TTS
â”‚   â”‚   â”‚   â”œâ”€â”€ resume_parser_service.py# Resume parsing
â”‚   â”‚   â”‚   â”œâ”€â”€ resume_analyzer_service.py# ATS scoring
â”‚   â”‚   â”‚   â”œâ”€â”€ job_scraper_service.py  # Job board scraping
â”‚   â”‚   â”‚   â”œâ”€â”€ opportunities_service.py# Job matching logic
â”‚   â”‚   â”‚   â””â”€â”€ journal_service.py      # Journal processing
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ models/                     # Database Models (SQLAlchemy)
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ database.py             # PostgreSQL models
â”‚   â”‚   â”‚   â””â”€â”€ graph_models.py         # Neo4j models
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ schemas/                    # Pydantic Schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py                 # User DTOs
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_schemas.py        # Graph DTOs
â”‚   â”‚   â”‚   â””â”€â”€ interview_schemas.py    # Interview DTOs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ config/                     # Configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ settings.py             # Environment variables
â”‚   â”‚   â”‚   â””â”€â”€ database.py             # DB connections
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ utils/                      # Utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                 # JWT helpers
â”‚   â”‚   â”‚   â”œâ”€â”€ graph_queries.py        # Cypher queries
â”‚   â”‚   â”‚   â””â”€â”€ graph_validators.py     # Data validation
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ knowledgeFiles/             # Static Knowledge
â”‚   â”‚   â”‚   â”œâ”€â”€ skillCatalog.json
â”‚   â”‚   â”‚   â”œâ”€â”€ skillOntology.json
â”‚   â”‚   â”‚   â”œâ”€â”€ jobRoles.json
â”‚   â”‚   â”‚   â”œâ”€â”€ jobSkill.json
â”‚   â”‚   â”‚   â””â”€â”€ resourceSkill.json
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ main.py                     # FastAPI app entry
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                         # AI Models
â”‚   â”‚   â”œâ”€â”€ whisper/
â”‚   â”‚   â”‚   â””â”€â”€ base.pt                 # Whisper Base model
â”‚   â”‚   â””â”€â”€ piper/
â”‚   â”‚       â”œâ”€â”€ en_US-lessac-medium.onnx
â”‚   â”‚       â””â”€â”€ en_US-lessac-medium.onnx.json
â”‚   â”‚
â”‚   â”œâ”€â”€ interview_audio/                # Generated Audio Files
â”‚   â”‚   â”œâ”€â”€ questions/                  # TTS-generated questions
â”‚   â”‚   â””â”€â”€ answers/                    # User answer recordings
â”‚   â”‚
â”‚   â”œâ”€â”€ interview_recordings/           # Full interview sessions
â”‚   â”‚
â”‚   â”œâ”€â”€ uploads/                        # User Uploads
â”‚   â”‚   â”œâ”€â”€ resumes/                    # Resume PDFs/DOCX
â”‚   â”‚   â””â”€â”€ temp/                       # Temporary files
â”‚   â”‚
â”‚   â”œâ”€â”€ alembic/                        # Database Migrations
â”‚   â”‚   â”œâ”€â”€ versions/                   # Migration scripts
â”‚   â”‚   â”œâ”€â”€ env.py
â”‚   â”‚   â””â”€â”€ script.py.mako
â”‚   â”‚
â”‚   â”œâ”€â”€ requirements.txt                # Core dependencies
â”‚   â”œâ”€â”€ requirements_opportunities.txt  # Scraping dependencies
â”‚   â”œâ”€â”€ req_interview.txt               # Interview dependencies
â”‚   â”œâ”€â”€ req_extra.txt                   # Additional packages
â”‚   â”œâ”€â”€ alembic.ini                     # Alembic config
â”‚   â”œâ”€â”€ init_db.py                      # DB initialization script
â”‚   â”œâ”€â”€ setup_local_models.sh           # Model download script
â”‚   â””â”€â”€ .env                            # Environment variables
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ LandingPage.tsx         # Marketing page
â”‚   â”‚   â”‚   â”œâ”€â”€ Login.tsx               # Authentication
â”‚   â”‚   â”‚   â”œâ”€â”€ GetStarted.tsx          # Registration wizard
â”‚   â”‚   â”‚   â”œâ”€â”€ Navbar.tsx              # Navigation
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.tsx       # Main container
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ DashboardHome.tsx   # Overview page
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProfileModule.tsx   # Profile management
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ResumeModule.tsx    # Resume tools
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ RoadmapModule.tsx   # Learning roadmap
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ OpportunitiesModule.tsx # Job search
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ JournalModule.tsx   # Daily journal
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ SummaryModule.tsx   # Progress reports
â”‚   â”‚   â”‚   â”‚
â”‚   â”‚   â”‚   â””â”€â”€ Interview/
â”‚   â”‚   â”‚       â”œâ”€â”€ InterviewModule.tsx # Interview hub
â”‚   â”‚   â”‚       â”œâ”€â”€ InterviewSetup.tsx  # Configuration
â”‚   â”‚   â”‚       â”œâ”€â”€ InterviewRoom.tsx   # Live session
â”‚   â”‚   â”‚       â”œâ”€â”€ InterviewResults.tsx# Results page
â”‚   â”‚   â”‚       â””â”€â”€ InterviewAnalytics.tsx # Historical data
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ services/                   # API Clients
â”‚   â”‚   â”‚   â”œâ”€â”€ apiService.ts           # Base HTTP client
â”‚   â”‚   â”‚   â”œâ”€â”€ authService.ts          # Auth APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ agentService.ts         # Agent APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ interviewService.ts     # Interview APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ resumeService.ts        # Resume APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ opportunitiesService.ts # Job APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ journalService.ts       # Journal APIs
â”‚   â”‚   â”‚   â”œâ”€â”€ profileService.ts       # Profile APIs
â”‚   â”‚   â”‚   â””â”€â”€ dashboardService.ts     # Dashboard APIs
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ index.css                   # Global styles
â”‚   â”‚   â””â”€â”€ App.tsx                     # Root component
â”‚   â”‚
â”‚   â”œâ”€â”€ index.html                      # HTML entry
â”‚   â”œâ”€â”€ index.tsx                       # React entry
â”‚   â”œâ”€â”€ vite.config.ts                  # Vite config
â”‚   â”œâ”€â”€ tsconfig.json                   # TypeScript config
â”‚   â”œâ”€â”€ package.json                    # Node dependencies
â”‚   â”œâ”€â”€ package-lock.json
â”‚   â””â”€â”€ .env.local                      # Environment variables
â”‚
â”œâ”€â”€ docs/                               # Documentation & Assets
â”‚   â””â”€â”€ images/                         # Screenshots & diagrams
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md                           # This file
```

***

## ğŸ“¸ Screenshots

### **Landing Page**

![Landing Page](./docs/images Upload & Auto-fill**

![Resume Upload](./docs/images/resume-upload-demod Home**

![Dashboard](./docs/images/dashboard-homeLearning Roadmap with Calendar Sync**

![Roadmap](./docs/images/roadmap-calendar Interview Room**

![Interview](./docs/images/interview-roomJob Matching Results**

![Jobs](./docs/images/job-matchesCold Email Automation**

![Cold Email](./docs/images/cold-email-dashboarDaily Journal & Insights**

![Journal](./docs/ ğŸ—ºï¸ Roadmap

### **Version 1.0 (Current)** âœ…

- Multi-agent AI system with LangGraph orchestration
- Resume parsing and auto-fill registration
- Voice-based AI interview simulator (Whisper + Piper TTS)
- Automated learning roadmap with Google Calendar sync
- Job scraping and matching (every 12 hours)
- Cold email automation (every 3 days)
- Daily journal with long-term memory (ChromaDB)
- Multi-database architecture (PostgreSQL + Neo4j + ChromaDB)

***

### **Version 2.0 (Upcoming)** ğŸš§

- [ ] **Real-time WebSocket Interviews** - Live transcription during answers
- [ ] **Mobile App** (React Native) - Interview practice on-the-go
- [ ] **Advanced Analytics Dashboard** - Skill growth visualization, time-series charts
- [ ] **Mentor Matching** - Connect with industry professionals via knowledge graph
- [ ] **Team Collaboration** - Study groups, peer resume reviews
- [ ] **Gamification** - Badges, streaks, leaderboards
- [ ] **Enhanced Cold Email** - A/B testing, open rate tracking
- [ ] **Multi-language Support** - Whisper multilingual models
- [ ] **Custom Agent Creation** - User-defined specialized agents

***

### **Version 3.0 (Vision)** ğŸ”®

- [ ] **Enterprise Features** - Team dashboards, org-wide skill mapping
- [ ] **Blockchain Credentials** - Verified skill certificates as NFTs
- [ ] **Metaverse Integration** - VR interview practice rooms
- [ ] **AI Video Interviewer** - Deepfake avatar with lip-sync
- [ ] **Salary Negotiation Coach** - Real-time guidance during offers

***

## ğŸ¤ Contributing

We welcome contributions from the community!

### **How to Contribute**

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** changes (`git commit -m 'Add amazing feature'`)
4. **Push** to branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### **Code Standards**

- **Python:** PEP 8, use type hints, docstrings for functions
- **TypeScript:** Airbnb style guide, functional components, TypeScript strict mode
- **Commits:** Conventional Commits format (`feat:`, `fix:`, `docs:`, etc.)

### **Testing**

```bash
# Backend tests
cd backend
pytest tests/ -v

# Frontend tests
cd frontend
npm test
```

***

## ğŸ“„ License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) for details.

***

## ğŸ“§ Contact & Support

- ğŸ’¬ **Discord:** [Join our community](https://discord.gg/careerai)
- ğŸ¦ **Twitter:** [@CareerAI_Dev](https://twitter.com/CareerAI_Dev)
- ğŸ“§ **Email:** support@careerai.dev
- ğŸ› **Issues:** [GitHub Issues](https://github.com/Seventie/Anokha-AiVerse/issues)

***

## ğŸ™ Acknowledgments

Special thanks to:

- **OpenAI** - GPT models and embeddings API
- **Groq** - Fast LLM inference
- **Whisper** - Open-source speech recognition
- **Piper** - Neural text-to-speech
- **LangChain & LangGraph** - Agent orchestration framework
- **Neo4j** - Knowledge graph database
- **ChromaDB** - Vector embedding database
- **FastAPI** - Modern Python web framework

***

<div align="center">

**â­ Star this repo if CareerAI helped you land your dream job!**

Built with â¤ï¸ by the CareerAI Team

![Footer](./docs/images/footer-er 30, 2025

</div>
