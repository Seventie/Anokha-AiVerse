# üöÄ CareerAI - AI-Powered Career Development Platform

<div align="center">

![CareerAI Banner](./Transform Your Career Journey with Intelligent AI Agents**

[](LICENSEn](https://img.shields.io/badge/python-3.11+-104+-ue -  [Architecture](#-system-architecture) -  [Installation](#-installation) -  [Usage](#-usage) -  [Documentation](#-documentation)

</div>

***

## üìã Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [System Architecture](#-system-architecture)
- [Technology Stack](#-technology-stack)
- [Installation](#-installation)
- [Configuration](#-configuration)
- [Usage](#-usage)
- [API Documentation](#-api-documentation)
- [Database Schemas](#-database-schemas)
- [AI Agents](#-ai-agents)
- [Contributing](#-contributing)
- [License](#-license)

***

## üåü Overview

CareerAI is a comprehensive, **agentic AI-powered platform** that revolutionizes career development through intelligent automation. Built with a microservice-oriented architecture, it leverages multiple specialized AI agents to provide personalized career guidance, interview preparation, opportunity matching, and skill development roadmaps.

![Platform Overview](./docs/images/platform CareerAI?

- **ü§ñ Multi-Agent System**: 8 specialized AI agents working collaboratively
- **üß† Knowledge Graph**: Neo4j-powered relationship modeling for skills, roles, and opportunities
- **üìä Multi-Database Architecture**: PostgreSQL, Neo4j, and ChromaDB working in harmony
- **üéØ Personalized Guidance**: Context-aware recommendations based on user profile and goals
- **üé§ AI Interview Practice**: Real-time voice-based mock interviews with instant feedback
- **üìà Career Roadmaps**: Dynamic, personalized learning paths generated by AI

***

## ‚ú® Key Features

### 1. **Intelligent User Onboarding**

![Onboarding Flow](./docs Parsing**: Automatic extraction of education, experience, skills, and projects
- **AI-Powered Form Filling**: Smart suggestions and autocomplete
- **Multi-Step Registration**: Guided profile creation with validation
- **Background Processing**: Asynchronous knowledge graph synchronization

**Technologies**: OpenAI GPT-4, Python-docx, PyPDF2, Pydantic validation

***

### 2. **AI Interview Simulator**

![Interview Module](./docs/images/interview- provides a realistic, voice-based interview experience powered by multiple AI technologies:

#### **Core Components**

- **Speech-to-Text (STT)**: Whisper Base model for accurate transcription
- **Text-to-Speech (TTS)**: Piper neural TTS for natural voice synthesis
- **Dynamic Question Generation**: Context-aware questions based on resume and role
- **Real-time Analysis**: Instant feedback on answers with scoring

#### **Interview Flow**

```
User Setup ‚Üí AI Voice Questions ‚Üí Voice/Text Answers ‚Üí 
Real-time Transcription ‚Üí AI Evaluation ‚Üí Detailed Analytics
```

#### **Key Features**

| Feature | Technology | Description |
|---------|-----------|-------------|
| **Voice Recognition** | Whisper Base (74M params) | Offline STT with 95%+ accuracy |
| **Voice Synthesis** | Piper TTS (en_US-lessac) | Natural, low-latency speech output |
| **Question Bank** | GPT-4 + Knowledge Graph | 100+ role-specific questions |
| **Answer Analysis** | LangChain + Custom Prompts | STAR method evaluation, scoring |
| **Performance Metrics** | PostgreSQL | Historical tracking, improvement trends |

![Interview Analytics](./docs/images/interview- Roadmap Generator**

![Roadmap Module](./docs/images/roadmap multi-phase learning paths using AI and knowledge graph traversal:

- **Skill Gap Analysis**: Compares current skills vs. target role requirements
- **Phase-based Learning**: Structured progression (Beginner ‚Üí Intermediate ‚Üí Advanced)
- **Resource Recommendations**: Curated courses, projects, and certifications
- **Progress Tracking**: Milestone-based achievement system

**AI Techniques**: Graph traversal algorithms, LLM-based content generation, embeddings similarity

***

### 4. **Opportunity Matching**

![Opportunities Module](./docs/images/opportunitiesd internship discovery with intelligent matching:

#### **Scraping & Aggregation**

- **Sources**: LinkedIn, Indeed, Glassdoor, AngelList
- **Real-time Updates**: Scheduled scrapers with Celery (future enhancement)
- **Data Cleaning**: NLP-based deduplication and normalization

#### **Matching Algorithm**

```python
Match Score = (
    Skills Match (40%) +
    Experience Match (30%) +
    Location Preference (15%) +
    Salary Expectation (10%) +
    Cultural Fit (5%)
)
```

#### **Recommendation Features**

- **Vector Similarity**: ChromaDB embeddings for semantic job matching
- **Graph-based Filtering**: Neo4j queries for skill path compatibility
- **Personalized Ranking**: User interaction history influences results

![Job Recommendations](./docs/images/ Analysis & Enhancement**

![Resume Module](./docs/images/resume. with actionable suggestions:

- **ATS Compatibility Score**: Keyword optimization for applicant tracking systems
- **Content Analysis**: Structure, formatting, and readability assessment
- **Achievement Highlighting**: Identifies quantifiable accomplishments
- **Version Control**: Multiple resume versions with A/B testing suggestions

**AI Models**: GPT-4 for content analysis, spaCy for NLP, custom scoring algorithms

***

### 6. **Learning Journal & Reflection**

![Journal Module](./docsd daily reflection and progress tracking:

- **Sentiment Analysis**: Tracks motivation and engagement over time
- **Goal Alignment**: Maps activities to career objectives
- **Insight Generation**: Weekly/monthly AI summaries
- **Habit Formation**: Gamified streaks and achievements

**Technologies**: Transformers (BERT), time-series analysis, LangChain

***

### 7. **Profile Intelligence**

![Profile Module](./docs profile management with AI-driven insights:

- **Completeness Score**: Identifies missing critical information
- **Competitive Analysis**: Benchmarks profile against industry standards
- **Visibility Optimization**: LinkedIn/portfolio enhancement suggestions
- **Network Mapping**: Visualizes career connections and potential mentors

***

## üèóÔ∏è System Architecture

### **High-Level Architecture**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                        Frontend Layer                            ‚îÇ
‚îÇ  React 18 + TypeScript + Vite + TailwindCSS + Lucide Icons     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ REST API (JSON)
                        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      Backend API Layer                           ‚îÇ
‚îÇ         FastAPI + Python 3.11 + Pydantic + JWT Auth            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ         ‚îÇ           ‚îÇ          ‚îÇ            ‚îÇ
        ‚ñº         ‚ñº           ‚ñº          ‚ñº            ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇPostgreSQL‚îÇNeo4j  ‚îÇ ‚îÇChromaDB ‚îÇ ‚îÇWhisper ‚îÇ ‚îÇPiper TTS ‚îÇ
   ‚îÇ  (SQL)  ‚îÇ(Graph)‚îÇ ‚îÇ(Vector) ‚îÇ ‚îÇ  (STT) ‚îÇ ‚îÇ  (Voice) ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

![Architecture Diagram](./docs/images/ **Multi-Agent System**

CareerAI employs **8 specialized AI agents** coordinated by a supervisor:

```
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Supervisor Agent ‚îÇ
                    ‚îÇ  (Orchestrator)  ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚ñº                    ‚ñº                    ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Profile Agent ‚îÇ    ‚îÇ Resume Agent ‚îÇ    ‚îÇRoadmap Agent ‚îÇ
‚îÇ (User Data)   ‚îÇ    ‚îÇ (Parsing)    ‚îÇ    ‚îÇ (Learning)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                    ‚îÇ                    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ Knowledge Graph  ‚îÇ
                    ‚îÇ    (Neo4j)       ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

![Agent Architecture](./docs/images/ **Agent Details**

| Agent | Purpose | Key Technologies |
|-------|---------|------------------|
| **Supervisor Agent** | Orchestrates agent collaboration, routing | LangChain, OpenAI GPT-4 |
| **Profile Agent** | Manages user data, skills, preferences | SQLAlchemy, Pydantic |
| **Resume Agent** | Parses and analyzes resumes | PyPDF2, python-docx, GPT-4 |
| **Interview Agent** | Conducts mock interviews | Whisper, Piper, LangChain |
| **Roadmap Agent** | Generates learning paths | Neo4j Cypher, GPT-4 |
| **Opportunities Agent** | Finds and matches jobs | BeautifulSoup, Selenium, ChromaDB |
| **Journal Agent** | Processes reflections | Transformers, sentiment analysis |
| **Summary Agent** | Creates progress reports | GPT-4, time-series analysis |

***

## üíª Technology Stack

### **Backend**

```yaml
Core Framework:
  - FastAPI 0.104+
  - Python 3.11+
  - Uvicorn (ASGI server)

Databases:
  - PostgreSQL 15 (Relational data)
  - Neo4j 5.0+ (Knowledge graph)
  - ChromaDB 0.4+ (Vector embeddings)

AI/ML:
  - OpenAI GPT-4 (LLM)
  - LangChain 0.1+ (Agent framework)
  - Whisper Base (Speech-to-text)
  - Piper TTS (Text-to-speech)
  - spaCy 3.7+ (NLP)
  - Transformers 4.35+ (BERT, sentence embeddings)

Authentication:
  - JWT (JSON Web Tokens)
  - bcrypt (Password hashing)

ORM & Validation:
  - SQLAlchemy 2.0+
  - Pydantic 2.0+
  - Alembic (Migrations)

File Processing:
  - PyPDF2 (PDF parsing)
  - python-docx (Word docs)
  - python-multipart (File uploads)

Web Scraping:
  - BeautifulSoup4
  - Selenium WebDriver
  - aiohttp (Async requests)
```

### **Frontend**

```yaml
Core:
  - React 18
  - TypeScript 5
  - Vite 5

UI Framework:
  - TailwindCSS 3.4
  - Lucide React (Icons)
  - Framer Motion (Animations)

State Management:
  - React Hooks
  - Context API

Audio/Video:
  - MediaRecorder API
  - Web Audio API
  - WebRTC (Future)

Build Tools:
  - Vite
  - ESLint
  - Prettier
```

### **DevOps & Infrastructure**

```yaml
Version Control:
  - Git
  - GitHub

Environment:
  - Python venv
  - Node.js 18+

Future Enhancements:
  - Docker & Docker Compose
  - Kubernetes
  - CI/CD (GitHub Actions)
  - Monitoring (Prometheus, Grafana)
```

***

## üì¶ Installation

### **Prerequisites**

- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **Node.js 18+** ([Download](https://nodejs.org/))
- **PostgreSQL 15+** ([Download](https://www.postgresql.org/download/))
- **Neo4j 5.0+** ([Download](https://neo4j.com/download/))
- **Git** ([Download](https://git-scm.com/downloads))

***

### **1. Clone Repository**

```bash
git clone https://github.com/Seventie/Anokha-AiVerse.git
cd Anokha-AiVerse
```

***

### **2. Backend Setup**

#### **Install Dependencies**

```bash
cd backend

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# Install Python packages
pip install -r requirements.txt
pip install -r requirements_opportunities.txt
pip install -r req_interview.txt
```

#### **Download AI Models**

```bash
# Run setup script (Linux/Mac)
chmod +x setup_local_models.sh
./setup_local_models.sh

# Or manually download:
# 1. Whisper Base model
python -c "import whisper; whisper.load_model('base')"

# 2. Piper TTS model (place in backend/models/piper/)
# Download from: https://github.com/rhasspy/piper/releases
```

#### **Environment Configuration**

Create `.env` file in `backend/`:

```env
# API Keys
OPENAI_API_KEY=your_openai_api_key_here

# Database URLs
DATABASE_URL=postgresql://user:password@localhost:5432/careerai
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_neo4j_password

# JWT Secret
SECRET_KEY=your_secret_key_here_use_strong_random_string
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# ChromaDB
CHROMA_PERSIST_DIRECTORY=./chroma_db

# File Storage
UPLOAD_DIR=./uploads
MAX_UPLOAD_SIZE=10485760  # 10MB

# AI Model Paths
WHISPER_MODEL_PATH=./models/whisper/base.pt
PIPER_MODEL_PATH=./models/piper/en_US-lessac-medium.onnx
```

#### **Initialize Databases**

```bash
# PostgreSQL - Create database
createdb careerai

# Run migrations
alembic upgrade head

# Initialize with demo data
python init_db.py

# Neo4j - Start Neo4j Desktop or Docker
# Then run knowledge graph initialization
python app/services/graph_builder.py
```

***

### **3. Frontend Setup**

```bash
cd ../frontend

# Install Node packages
npm install

# Create .env.local
cat > .env.local << EOF
VITE_API_URL=http://localhost:8000
VITE_WS_URL=ws://localhost:8000
EOF
```

***

### **4. Run Application**

**Terminal 1 - Backend:**

```bash
cd backend
source venv/bin/activate  # or venv\Scripts\activate on Windows
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Terminal 2 - Frontend:**

```bash
cd frontend
npm run dev
```

**Access Application:**

- Frontend: http://localhost:5173
- Backend API: http://localhost:8000
- API Docs: http://localhost:8000/docs

![Installation Success](./docs/images/installation- ‚öôÔ∏è Configuration

### **Database Configuration**

#### **PostgreSQL Schema**

The application uses the following main tables:

```sql
-- Users and Authentication
users (id, email, username, hashed_password, full_name, location, ...)

-- Profile Data
education (id, user_id, institution, degree, major, ...)
experience (id, user_id, role, company, duration, ...)
skills (id, user_id, skill, category, level, ...)
projects (id, user_id, title, description, tech_stack, ...)

-- Career Planning
career_goals (id, user_id, target_roles, target_timeline, ...)
availability (id, user_id, free_time, study_days, ...)
preferred_locations (id, user_id, location, priority, ...)

-- Interview System
interviews (id, user_id, role, difficulty, status, ...)
interview_questions (id, interview_id, question_text, question_type, ...)
interview_responses (id, question_id, answer_text, score, feedback, ...)

-- Opportunities
opportunities (id, title, company, location, salary_range, ...)
user_opportunity_interactions (id, user_id, opportunity_id, status, ...)

-- Learning Journal
journal_entries (id, user_id, entry_text, sentiment_score, ...)
```

![Database Schema](./docs/images/ **Neo4j Knowledge Graph**

The knowledge graph models relationships between:

```cypher
// Node Types
(:User {id, name, email, skills})
(:Skill {name, category, difficulty})
(:Role {title, seniority, industry})
(:Resource {name, type, url})
(:Company {name, size, industry})

// Relationship Types
(:User)-[:HAS_SKILL {level}]->(:Skill)
(:User)-[:TARGETS]->(:Role)
(:Role)-[:REQUIRES {importance}]->(:Skill)
(:Skill)-[:PREREQUISITE_FOR]->(:Skill)
(:Resource)-[:TEACHES]->(:Skill)
(:Company)-[:OFFERS]->(:Role)
```

**Example Query:**

```cypher
// Find skill gaps for user targeting Software Engineer role
MATCH (u:User {id: $user_id})-[:HAS_SKILL]->(userSkills:Skill)
MATCH (targetRole:Role {title: "Software Engineer"})-[:REQUIRES]->(requiredSkills:Skill)
WHERE NOT (u)-[:HAS_SKILL]->(requiredSkills)
RETURN requiredSkills.name AS skill_to_learn, 
       requiredSkills.category AS category
ORDER BY requiredSkills.importance DESC
```

![Knowledge Graph](./docs/images/ **ChromaDB Vector Store**

ChromaDB stores vector embeddings for semantic search:

```python
# Collections
- resume_embeddings: Resume content vectors
- project_descriptions: Project detail vectors
- career_intents: Vision statement vectors
- opportunity_embeddings: Job description vectors

# Embedding Model: OpenAI text-embedding-ada-002
# Similarity Metric: Cosine similarity
```

***

## üöÄ Usage

### **1. User Registration**

![Registration Flow](./docs/images/registration-t registrationData = {
  email: "user@example.com",
  username: "johndoe",
  password: "SecurePass123!",
  full_name: "John Doe",
  location: "San Francisco, CA",
  preferred_locations: ["San Francisco", "New York", "Austin"],
  education: [{
    institution: "Stanford University",
    degree: "Bachelor's",
    major: "Computer Science",
    duration: "2019-2023"
  }],
  skills: {
    technical: ["React", "Python", "Machine Learning"],
    soft: ["Leadership", "Communication"]
  },
  target_role: "Software Engineer",
  timeline: "6 Months"
};
```

**Backend Processing:**

```python
# app/routes/auth.py
@router.post("/register")
async def register(user_data: UserRegister, background_tasks: BackgroundTasks):
    # 1. Create user in PostgreSQL
    # 2. Store resume embeddings in ChromaDB
    # 3. Schedule background task for Neo4j sync
    background_tasks.add_task(sync_user_to_graph_background, user_id)
    return UserRegisterResponse(user, access_token, token_type)
```

***

### **2. AI Interview**

![Interview Session](./docs/images/interview- an Interview**

```typescript
// Frontend: InterviewSetup.tsx
const startInterview = async () => {
  const config = {
    role: "Software Engineer",
    difficulty: "medium",
    duration: 30,  // minutes
    includeResume: true,
    includeProjects: true
  };
  
  const response = await interviewService.startInterview(config);
  // Returns: interview_id, first_question, question_audio_url
};
```

#### **Question Generation**

```python
# app/agents/interview_agent.py
async def generate_questions(user_profile, role, difficulty):
    # 1. Analyze user's resume and projects from PostgreSQL
    # 2. Query Neo4j for role-specific skill requirements
    # 3. Use GPT-4 to generate contextual questions
    # 4. Synthesize questions using Piper TTS
    # 5. Store question audio in interview_audio/questions/
    return questions_with_audio
```

#### **Answer Processing**

```python
# app/services/stt_service.py
async def transcribe_answer(audio_file):
    # 1. Receive WebM audio from frontend
    # 2. Convert to WAV if needed
    # 3. Transcribe using Whisper Base model
    model = whisper.load_model("base")
    result = model.transcribe(audio_file)
    return result["text"]

# app/agents/interview_agent.py
async def evaluate_answer(question, answer, context):
    # 1. Score using STAR method criteria
    # 2. Check technical accuracy
    # 3. Assess communication clarity
    # 4. Generate personalized feedback
    return {
        "score": 8.5,
        "feedback": "Strong answer with clear examples...",
        "improvement_areas": ["Add more metrics", "Shorten introduction"]
    }
```

***

### **3. Career Roadmap**

![Roadmap Generation](./docs/images/roadmap
async def generate_roadmap(user_id, target_role, timeline):
    # 1. Get current user skills from PostgreSQL
    user_skills = await get_user_skills(user_id)
    
    # 2. Query Neo4j for skill path
    query = """
    MATCH (u:User {id: $user_id})-[:HAS_SKILL]->(currentSkills:Skill)
    MATCH (targetRole:Role {title: $target_role})-[:REQUIRES]->(requiredSkills:Skill)
    MATCH path = shortestPath((currentSkills)-[:PREREQUISITE_FOR*]->(requiredSkills))
    RETURN path, requiredSkills
    """
    
    # 3. Generate phased learning plan
    phases = create_learning_phases(skill_gaps, timeline)
    
    # 4. Recommend resources from knowledge graph
    for phase in phases:
        phase['resources'] = await get_learning_resources(phase['skills'])
    
    return {
        "phases": phases,
        "total_duration": "6 months",
        "completion_metrics": {...}
    }
```

***

### **4. Job Opportunities**

![Job Matching](./docs/images/aping Jobs**

```python
# app/services/job_scraper_service.py
async def scrape_jobs(keywords, location):
    # 1. Scrape from LinkedIn, Indeed, Glassdoor
    jobs = await scrape_all_sources(keywords, location)
    
    # 2. Clean and deduplicate
    cleaned_jobs = clean_job_data(jobs)
    
    # 3. Store in PostgreSQL
    for job in cleaned_jobs:
        await store_opportunity(job)
    
    # 4. Generate embeddings for ChromaDB
    embeddings = generate_job_embeddings(cleaned_jobs)
    chromadb.add(embeddings)
```

#### **Matching Algorithm**

```python
# app/services/opportunities_service.py
async def match_opportunities(user_id, filters):
    # 1. Get user profile and preferences
    user_profile = await get_user_profile(user_id)
    
    # 2. Vector search in ChromaDB for semantic matching
    similar_jobs = chromadb.query(
        query_embeddings=user_profile_embedding,
        n_results=50
    )
    
    # 3. Filter by Neo4j skill requirements
    filtered_jobs = await filter_by_skill_match(similar_jobs, user_id)
    
    # 4. Rank by composite score
    ranked_jobs = rank_opportunities(filtered_jobs, user_profile)
    
    return ranked_jobs[:20]  # Top 20 matches
```

***

## üìñ API Documentation

### **Authentication**

#### **POST /api/auth/register**

Register a new user.

**Request Body:**

```json
{
  "email": "user@example.com",
  "username": "johndoe",
  "password": "SecurePass123!",
  "full_name": "John Doe",
  "location": "San Francisco, CA",
  "preferred_locations": ["San Francisco", "New York"],
  "education": [...],
  "experience": [...],
  "skills": {"technical": [...], "soft": [...]},
  "target_role": "Software Engineer",
  "timeline": "6 Months"
}
```

**Response:**

```json
{
  "user": {
    "id": "uuid",
    "email": "user@example.com",
    "full_name": "John Doe",
    ...
  },
  "access_token": "eyJ0eXAiOiJKV1QiLC...",
  "token_type": "bearer"
}
```

***

#### **POST /api/auth/login**

Authenticate user.

**Request Body:**

```json
{
  "email": "user@example.com",
  "password": "SecurePass123!"
}
```

**Response:**

```json
{
  "access_token": "eyJ0eXAiOiJKV1QiLC...",
  "token_type": "bearer"
}
```

***

### **Interview Module**

#### **POST /api/interview/start**

Start a new interview session.

**Headers:** `Authorization: Bearer <token>`

**Request Body:**

```json
{
  "role": "Software Engineer",
  "difficulty": "medium",
  "duration": 30,
  "include_resume": true
}
```

**Response:**

```json
{
  "interview_id": "uuid",
  "questions": [
    {
      "id": "uuid",
      "question_text": "Tell me about a time you optimized system performance.",
      "question_audio_url": "/interview_audio/questions/question_1.wav",
      "question_type": "behavioral"
    }
  ],
  "total_questions": 10
}
```

***

#### **POST /api/interview/{interview_id}/answer**

Submit answer to interview question.

**Headers:** `Authorization: Bearer <token>`

**Request Body (multipart/form-data):**

```
audio_file: <audio_blob.webm>
question_id: "uuid"
answer_text: "In my previous role, I identified a bottleneck..."
```

**Response:**

```json
{
  "score": 8.5,
  "feedback": "Strong answer with clear STAR structure...",
  "improvement_areas": ["Add quantifiable metrics"],
  "next_question": {
    "id": "uuid",
    "question_text": "...",
    "question_audio_url": "..."
  }
}
```

***

### **Career Roadmap**

#### **GET /api/roadmap/generate**

Generate personalized career roadmap.

**Headers:** `Authorization: Bearer <token>`

**Query Parameters:**
- `target_role`: "Software Engineer"
- `timeline`: "6 Months"

**Response:**

```json
{
  "roadmap_id": "uuid",
  "phases": [
    {
      "phase_number": 1,
      "title": "Foundation (Weeks 1-8)",
      "skills_to_learn": ["Data Structures", "Algorithms"],
      "resources": [
        {
          "title": "LeetCode Patterns",
          "type": "course",
          "url": "https://...",
          "duration": "40 hours"
        }
      ],
      "projects": [...]
    },
    ...
  ],
  "total_duration": "6 months",
  "estimated_effort": "15 hours/week"
}
```

***

### **Opportunities**

#### **GET /api/opportunities/search**

Search and match job opportunities.

**Headers:** `Authorization: Bearer <token>`

**Query Parameters:**
- `keywords`: "Software Engineer"
- `location`: "San Francisco"
- `remote`: true
- `experience_level`: "mid"
- `page`: 1
- `limit`: 20

**Response:**

```json
{
  "opportunities": [
    {
      "id": "uuid",
      "title": "Senior Software Engineer",
      "company": "Tech Corp",
      "location": "San Francisco, CA",
      "salary_range": "$150k-$200k",
      "match_score": 92.5,
      "match_reasons": [
        "95% skill match",
        "Location preference",
        "Salary expectations met"
      ],
      "description": "...",
      "required_skills": ["Python", "React", "AWS"],
      "posted_date": "2025-12-15"
    },
    ...
  ],
  "total_results": 156,
  "page": 1,
  "pages": 8
}
```

***

## üóÑÔ∏è Database Schemas

### **PostgreSQL Entity-Relationship Diagram**

![PostgreSQL ER Diagram](./docs/images/postgresql-er-diagram.pngd UUID PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    username VARCHAR(100) UNIQUE NOT NULL,
    hashed_password VARCHAR(255) NOT NULL,
    full_name VARCHAR(255),
    location VARCHAR(255),
    readiness_level VARCHAR(50),
    is_demo BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User Profile Details
CREATE TABLE education (
    id SERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    institution VARCHAR(255) NOT NULL,
    degree VARCHAR(100),
    major VARCHAR(100),
    location VARCHAR(255),
    duration VARCHAR(100),
    start_date DATE,
    end_date DATE,
    grade VARCHAR(50),
    is_confirmed BOOLEAN DEFAULT TRUE
);

CREATE TABLE experience (
    id SERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    role VARCHAR(255) NOT NULL,
    company VARCHAR(255) NOT NULL,
    location VARCHAR(255),
    duration VARCHAR(100),
    description TEXT,
    start_date DATE,
    end_date DATE,
    is_confirmed BOOLEAN DEFAULT TRUE
);

CREATE TABLE skills (
    id SERIAL PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    skill VARCHAR(100) NOT NULL,
    category VARCHAR(50),  -- 'TECHNICAL' or 'SOFT'
    level VARCHAR(50),     -- 'BEGINNER', 'INTERMEDIATE', 'ADVANCED'
    verified BOOLEAN DEFAULT FALSE,
    is_confirmed BOOLEAN DEFAULT TRUE
);

-- Interview System
CREATE TABLE interviews (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id) ON DELETE CASCADE,
    role VARCHAR(255) NOT NULL,
    difficulty VARCHAR(50),  -- 'easy', 'medium', 'hard'
    status VARCHAR(50),      -- 'in_progress', 'completed', 'abandoned'
    total_score DECIMAL(5,2),
    started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    completed_at TIMESTAMP
);

CREATE TABLE interview_questions (
    id UUID PRIMARY KEY,
    interview_id UUID REFERENCES interviews(id) ON DELETE CASCADE,
    question_text TEXT NOT NULL,
    question_type VARCHAR(50),  -- 'behavioral', 'technical', 'situational'
    question_audio_path VARCHAR(512),
    sequence_number INTEGER
);

CREATE TABLE interview_responses (
    id UUID PRIMARY KEY,
    question_id UUID REFERENCES interview_questions(id) ON DELETE CASCADE,
    answer_text TEXT,
    answer_audio_path VARCHAR(512),
    transcription_text TEXT,
    score DECIMAL(5,2),
    feedback TEXT,
    evaluation_metrics JSONB,
    answered_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Opportunities
CREATE TABLE opportunities (
    id UUID PRIMARY KEY,
    title VARCHAR(255) NOT NULL,
    company VARCHAR(255),
    location VARCHAR(255),
    remote BOOLEAN DEFAULT FALSE,
    salary_range VARCHAR(100),
    experience_level VARCHAR(50),
    description TEXT,
    requirements TEXT,
    source VARCHAR(100),  -- 'linkedin', 'indeed', 'glassdoor'
    source_url VARCHAR(512),
    posted_date DATE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

***

### **Neo4j Graph Schema**

![Neo4j Graph Schema](./docs/images/neo(u:User {
    id: $user_id,
    name: $name,
    email: $email,
    target_role: $target_role,
    created_at: datetime()
})

// Create Skill Nodes with Hierarchy
CREATE (s1:Skill {
    name: "Python",
    category: "Programming Language",
    difficulty: "intermediate"
})
CREATE (s2:Skill {
    name: "Django",
    category: "Web Framework",
    difficulty: "intermediate"
})
CREATE (s2)-[:REQUIRES]->(s1)  // Django requires Python

// Link User to Skills
MATCH (u:User {id: $user_id}), (s:Skill {name: $skill_name})
CREATE (u)-[:HAS_SKILL {
    level: $level,
    verified: $verified,
    acquired_date: date()
}]->(s)

// Create Role with Requirements
CREATE (r:Role {
    title: "Full Stack Developer",
    seniority: "mid",
    industry: "Technology"
})
MATCH (s:Skill {name: "React"})
CREATE (r)-[:REQUIRES {
    importance: 9,  // Scale 1-10
    years_experience: 2
}]->(s)

// Skill Learning Paths
MATCH (s1:Skill {name: "HTML"}), (s2:Skill {name: "CSS"}), (s3:Skill {name: "JavaScript"})
CREATE (s1)-[:PREREQUISITE_FOR {order: 1}]->(s2)
CREATE (s2)-[:PREREQUISITE_FOR {order: 2}]->(s3)

// Learning Resources
CREATE (r:Resource {
    name: "React Official Docs",
    type: "documentation",
    url: "https://react.dev",
    difficulty: "beginner"
})
MATCH (s:Skill {name: "React"}), (r:Resource {name: "React Official Docs"})
CREATE (r)-[:TEACHES {effectiveness: 9}]->(s)
```

***

### **ChromaDB Collections**

![ChromaDB Architecture](./docs/images/chromss VectorDB:
    def __init__(self):
        self.client = chromadb.PersistentClient(path="./chroma_db")
        
        # Collection: Resume Embeddings
        self.resume_collection = self.client.get_or_create_collection(
            name="resume_embeddings",
            metadata={"description": "Resume content vectors for semantic search"}
        )
        
        # Collection: Project Descriptions
        self.project_collection = self.client.get_or_create_collection(
            name="project_descriptions",
            metadata={"description": "Project detail embeddings"}
        )
        
        # Collection: Career Intents
        self.intent_collection = self.client.get_or_create_collection(
            name="career_intents",
            metadata={"description": "Vision statement embeddings"}
        )
        
        # Collection: Job Opportunities
        self.opportunity_collection = self.client.get_or_create_collection(
            name="opportunity_embeddings",
            metadata={"description": "Job description vectors"}
        )
    
    async def add_resume(self, user_id, resume_text):
        embedding = await generate_embedding(resume_text)
        self.resume_collection.add(
            ids=[f"resume_{user_id}"],
            embeddings=[embedding],
            metadatas=[{"user_id": user_id, "indexed_at": datetime.now().isoformat()}]
        )
    
    async def search_similar_opportunities(self, user_profile, n_results=20):
        user_embedding = await generate_embedding(user_profile)
        results = self.opportunity_collection.query(
            query_embeddings=[user_embedding],
            n_results=n_results
        )
        return results
```

**Embedding Model Configuration:**

```python
# OpenAI text-embedding-ada-002
EMBEDDING_MODEL = "text-embedding-ada-002"
EMBEDDING_DIMENSIONS = 1536
SIMILARITY_METRIC = "cosine"
```

***

## ü§ñ AI Agents

### **Agent System Architecture**

![Agent System](./docs/images/agent-system built using the LangChain framework with custom tools and prompts:

```python
# app/agents/base_agent.py

from langchain.agents import AgentExecutor, create_openai_functions_agent
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

class BaseAgent:
    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.7)
        self.tools = []
        self.memory = ConversationBufferMemory()
    
    def add_tool(self, tool):
        self.tools.append(tool)
    
    def create_agent(self, system_prompt: str):
        prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
            ("ai", "{agent_scratchpad}")
        ])
        
        agent = create_openai_functions_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
        
        return AgentExecutor(agent=agent, tools=self.tools, verbose=True)
```

***

### **1. Supervisor Agent**

**Purpose:** Orchestrates agent collaboration and routing.

```python
# app/agents/supervisor_agent.py

class SupervisorAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="Supervisor",
            description="Coordinates multiple specialized agents"
        )
        
        self.system_prompt = """
        You are a supervisor agent coordinating specialized career development agents.
        
        Available agents:
        - ProfileAgent: Manages user profile and preferences
        - ResumeAgent: Parses and analyzes resumes
        - RoadmapAgent: Generates learning paths
        - InterviewAgent: Conducts mock interviews
        - OpportunitiesAgent: Finds and matches jobs
        
        Your task is to:
        1. Understand user request
        2. Determine which agent(s) to invoke
        3. Coordinate agent interactions
        4. Synthesize final response
        """
    
    async def route_request(self, user_request: str, user_context: dict):
        # Analyze request and determine agent routing
        routing_decision = await self.analyze_request(user_request)
        
        results = []
        for agent_name in routing_decision['agents']:
            agent = self.get_agent(agent_name)
            result = await agent.execute(user_request, user_context)
            results.append(result)
        
        # Synthesize results
        final_response = await self.synthesize_results(results)
        return final_response
```

***

### **2. Interview Agent**

**Purpose:** Conducts AI-powered mock interviews.

```python
# app/agents/interview_agent.py

class InterviewAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="Interview Agent",
            description="Conducts mock interviews and evaluates responses"
        )
        
        # Add specialized tools
        self.add_tool(QuestionGeneratorTool())
        self.add_tool(AnswerEvaluatorTool())
        self.add_tool(STTTool())
        self.add_tool(TTSTool())
    
    async def generate_questions(self, role: str, difficulty: str, user_profile: dict):
        """Generate contextual interview questions"""
        
        prompt = f"""
        Generate {difficulty} interview questions for a {role} position.
        
        Candidate Background:
        - Skills: {user_profile['skills']}
        - Experience: {user_profile['experience']}
        - Projects: {user_profile['projects']}
        
        Question Types:
        1. Behavioral (STAR method)
        2. Technical (role-specific)
        3. Situational (problem-solving)
        
        Ensure questions are:
        - Relevant to candidate's background
        - Appropriate for difficulty level
        - Diverse in coverage
        """
        
        questions = await self.llm.ainvoke(prompt)
        
        # Synthesize audio for each question
        for question in questions:
            audio_path = await self.synthesize_speech(question['text'])
            question['audio_url'] = audio_path
        
        return questions
    
    async def evaluate_answer(self, question: str, answer: str, criteria: dict):
        """Evaluate answer using multiple criteria"""
        
        evaluation_prompt = f"""
        Evaluate this interview answer:
        
        Question: {question}
        Answer: {answer}
        
        Criteria:
        1. Relevance (1-10): Does it answer the question?
        2. Structure (1-10): STAR method for behavioral questions
        3. Clarity (1-10): Communication effectiveness
        4. Technical Accuracy (1-10): For technical questions
        5. Depth (1-10): Level of detail and insight
        
        Provide:
        - Overall score (weighted average)
        - Strengths (3-5 points)
        - Improvement areas (3-5 points)
        - Revised answer example
        """
        
        evaluation = await self.llm.ainvoke(evaluation_prompt)
        return evaluation
```

**Question Audio Synthesis:**

```python
# app/services/tts_service.py

import subprocess
from pathlib import Path

class TTSService:
    def __init__(self, model_path: str = "./models/piper/en_US-lessac-medium.onnx"):
        self.model_path = model_path
        self.output_dir = Path("./interview_audio/questions")
    
    async def synthesize(self, text: str, output_filename: str) -> str:
        """Convert text to speech using Piper TTS"""
        
        output_path = self.output_dir / output_filename
        
        # Run Piper TTS command
        command = [
            "piper",
            "--model", self.model_path,
            "--output_file", str(output_path)
        ]
        
        process = subprocess.Popen(
            command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )
        
        stdout, stderr = process.communicate(input=text.encode())
        
        if process.returncode != 0:
            raise Exception(f"TTS failed: {stderr.decode()}")
        
        return f"/interview_audio/questions/{output_filename}"
```

**Answer Transcription:**

```python
# app/services/stt_service.py

import whisper

class STTService:
    def __init__(self, model_name: str = "base"):
        self.model = whisper.load_model(model_name)
    
    async def transcribe(self, audio_file_path: str) -> dict:
        """Transcribe audio using Whisper"""
        
        result = self.model.transcribe(
            audio_file_path,
            language="en",
            task="transcribe",
            fp16=False  # Use FP32 for CPU
        )
        
        return {
            "text": result["text"],
            "segments": result["segments"],
            "language": result["language"]
        }
```

***

### **3. Roadmap Agent**

**Purpose:** Generates personalized career learning paths.

```python
# app/agents/roadmap_agent.py

class RoadmapAgent(BaseAgent):
    def __init__(self):
        super().__init__(
            name="Roadmap Agent",
            description="Creates personalized career development roadmaps"
        )
        
        self.add_tool(SkillGapAnalysisTool())
        self.add_tool(GraphTraversalTool())
        self.add_tool(ResourceRecommenderTool())
    
    async def generate_roadmap(
        self,
        user_id: str,
        target_role: str,
        timeline: str,
        current_skills: List[str]
    ) -> dict:
        """Generate comprehensive learning roadmap"""
        
        # 1. Analyze skill gaps
        required_skills = await self.get_role_requirements(target_role)
        skill_gaps = self.calculate_gaps(current_skills, required_skills)
        
        # 2. Find optimal learning path in Neo4j
        learning_path = await self.find_skill_path(current_skills, skill_gaps)
        
        # 3. Generate phased plan
        phases = self.create_phases(learning_path, timeline)
        
        # 4. Recommend resources for each phase
        for phase in phases:
            phase['resources'] = await self.recommend_resources(phase['skills'])
            phase['projects'] = await self.suggest_projects(phase['skills'])
        
        # 5. Create milestones and metrics
        roadmap = {
            "target_role": target_role,
            "timeline": timeline,
            "phases": phases,
            "milestones": self.create_milestones(phases),
            "success_metrics": self.define_metrics(target_role)
        }
        
        return roadmap
    
    async def find_skill_path(self, current_skills: List[str], target_skills: List[str]):
        """Find optimal learning path using Neo4j graph traversal"""
        
        query = """
        MATCH (current:Skill) WHERE current.name IN $current_skills
        MATCH (target:Skill) WHERE target.name IN $target_skills
        MATCH path = shortestPath((current)-[:PREREQUISITE_FOR*]->(target))
        RETURN path, length(path) AS path_length
        ORDER BY path_length ASC
        """
        
        result = await self.graph_db.execute_query(query, {
            "current_skills": current_skills,
            "target_skills": target_skills
        })
        
        return self.parse_skill_path(result)
```

***

## üé® Frontend Components

### **Component Structure**

```
frontend/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ LandingPage.tsx          # Marketing homepage
‚îÇ   ‚îú‚îÄ‚îÄ Login.tsx                # Authentication
‚îÇ   ‚îú‚îÄ‚îÄ GetStarted.tsx           # Multi-step registration
‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.tsx            # Main dashboard container
‚îÇ   ‚îú‚îÄ‚îÄ Dashboard/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ DashboardHome.tsx    # Overview & metrics
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ProfileModule.tsx    # Profile management
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ResumeModule.tsx     # Resume upload & analysis
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ RoadmapModule.tsx    # Learning path visualization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ OpportunitiesModule.tsx  # Job search & matching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ JournalModule.tsx    # Daily reflections
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ SummaryModule.tsx    # Progress reports
‚îÇ   ‚îî‚îÄ‚îÄ Interview/
‚îÇ       ‚îú‚îÄ‚îÄ InterviewModule.tsx  # Interview hub
‚îÇ       ‚îú‚îÄ‚îÄ InterviewSetup.tsx   # Configuration
‚îÇ       ‚îú‚îÄ‚îÄ InterviewRoom.tsx    # Live interview session
‚îÇ       ‚îú‚îÄ‚îÄ InterviewResults.tsx # Performance review
‚îÇ       ‚îî‚îÄ‚îÄ InterviewAnalytics.tsx  # Historical analytics
‚îî‚îÄ‚îÄ services/
    ‚îú‚îÄ‚îÄ apiService.ts            # Base API client
    ‚îú‚îÄ‚îÄ authService.ts           # Authentication
    ‚îú‚îÄ‚îÄ interviewService.ts      # Interview APIs
    ‚îú‚îÄ‚îÄ resumeService.ts         # Resume processing
    ‚îú‚îÄ‚îÄ opportunitiesService.ts  # Job matching
    ‚îî‚îÄ‚îÄ journalService.ts        # Journal entries
```

![Frontend Architecture](./docs/images/ **Key UI Components**

#### **Interview Room**

```typescript
// frontend/components/Interview/InterviewRoom.tsx

const InterviewRoom: React.FC = () => {
  const [isRecording, setIsRecording] = useState(false);
  const [currentQuestion, setCurrentQuestion] = useState<Question | null>(null);
  const [audioBlob, setAudioBlob] = useState<Blob | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  
  // Initialize MediaRecorder
  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
    
    const chunks: Blob[] = [];
    mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
    mediaRecorder.onstop = () => {
      const blob = new Blob(chunks, { type: 'audio/webm' });
      setAudioBlob(blob);
      submitAnswer(blob);
    };
    
    mediaRecorder.start();
    mediaRecorderRef.current = mediaRecorder;
    setIsRecording(true);
  };
  
  const stopRecording = () => {
    mediaRecorderRef.current?.stop();
    setIsRecording(false);
  };
  
  // Submit answer to backend
  const submitAnswer = async (audioBlob: Blob) => {
    const formData = new FormData();
    formData.append('audio_file', audioBlob, 'answer.webm');
    formData.append('question_id', currentQuestion.id);
    
    const response = await interviewService.submitAnswer(
      interviewId,
      formData
    );
    
    // Display feedback and next question
    showFeedback(response.feedback);
    setCurrentQuestion(response.next_question);
    playQuestionAudio(response.next_question.audio_url);
  };
  
  return (
    <div className="interview-room">
      {/* Question Display */}
      <div className="question-card">
        <h2>{currentQuestion?.question_text}</h2>
        <audio ref={audioRef} src={currentQuestion?.audio_url} autoPlay />
      </div>
      
      {/* Recording Controls */}
      <div className="controls">
        {!isRecording ? (
          <button onClick={startRecording}>
            <Mic size={32} /> Start Answer
          </button>
        ) : (
          <button onClick={stopRecording}>
            <Square size={32} /> Submit Answer
          </button>
        )}
      </div>
      
      {/* Visual Feedback */}
      {isRecording && <WaveformVisualizer />}
    </div>
  );
};
```

***

## üîß Advanced Features

### **Real-time WebSocket Communication**

Future enhancement for live interview feedback:

```python
# app/routes/interview.py (Future)

from fastapi import WebSocket, WebSocketDisconnect

@router.websocket("/ws/interview/{interview_id}")
async def interview_websocket(websocket: WebSocket, interview_id: str):
    await websocket.accept()
    
    try:
        while True:
            # Receive audio chunks in real-time
            audio_chunk = await websocket.receive_bytes()
            
            # Stream to Whisper for live transcription
            transcription = await stt_service.transcribe_stream(audio_chunk)
            
            # Send live transcription back to frontend
            await websocket.send_json({
                "type": "transcription",
                "text": transcription
            })
    
    except WebSocketDisconnect:
        logger.info(f"Interview {interview_id} WebSocket disconnected")
```

***

### **Background Job Processing**

Using Celery for async tasks (future enhancement):

```python
# app/tasks/celery_tasks.py (Future)

from celery import Celery

celery_app = Celery('careerai', broker='redis://localhost:6379/0')

@celery_app.task
def scrape_job_postings(keywords: List[str], locations: List[str]):
    """Asynchronous job scraping"""
    scraper = JobScraperService()
    jobs = scraper.scrape_all_sources(keywords, locations)
    
    # Store in database
    for job in jobs:
        store_opportunity(job)
    
    # Generate embeddings
    generate_job_embeddings(jobs)

@celery_app.task
def sync_user_to_knowledge_graph(user_id: str):
    """Background sync of user data to Neo4j"""
    sync_service = UserGraphSync()
    sync_service.sync_complete_user(user_id)
```

***

## üìä Monitoring & Analytics

### **Performance Metrics**

![Analytics Dashboard](./docs/images/analyticstheus_client import Counter, Histogram, Gauge

# Define metrics
interview_started = Counter('interview_started_total', 'Total interviews started')
interview_completed = Counter('interview_completed_total', 'Total interviews completed')
interview_duration = Histogram('interview_duration_seconds', 'Interview duration')
active_users = Gauge('active_users', 'Currently active users')

# Record metrics
@router.post("/interview/start")
async def start_interview():
    interview_started.inc()
    # ... rest of the code
```

***

## üöß Future Enhancements

### **Planned Features**

1. **Mobile Application**
   - React Native mobile app
   - Offline interview practice
   - Push notifications for opportunities

2. **Advanced Analytics**
   - Predictive job market trends
   - Salary negotiation insights
   - Network effect modeling

3. **Gamification**
   - Achievement badges
   - Leaderboards
   - Daily challenges

4. **Social Features**
   - Peer review for resumes
   - Mentor matching
   - Study groups

5. **Enterprise Features**
   - Team dashboards
   - Organization-wide skill mapping
   - Bulk user management

![Roadmap](./docs/images/ ü§ù Contributing

We welcome contributions! Please follow these guidelines:

### **Development Workflow**

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### **Code Standards**

- **Python**: Follow PEP 8, use type hints
- **TypeScript**: Follow Airbnb style guide
- **Commits**: Use conventional commits format

### **Testing**

```bash
# Backend tests
cd backend
pytest tests/

# Frontend tests
cd frontend
npm test
```

***

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

***

## üë• Contributors

<div align="center">

[![Contributors](https://contrib.rocks/image?repo=Seventieibutors üìß Contact & Support

- **Email**: support@careerai.dev
- **Discord**: [Join our community](https://discord.gg/careerai)
- **Twitter**: [@CareerAI_Dev](https://twitter.com/CareerAI_Dev)

***

<div align="center">

**‚≠ê Star this repo if CareerAI helped you!**

Made with ‚ù§Ô∏è by the CareerAI Team

![Footer](./docs/images/footer-

